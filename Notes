For the existing Trash/Celery dashboard in Grafana:

Singlestat round guauge to show workers:  (Gauge)
sum(celery_workers{job=~"$job"})   (Singlestat round gauge)         (/api/tasks:  name and state?)

Summary task by status: (Gauge)
sum(rate(celery_tasks{job=~"$job"}[$TIME_FRAME])) by (state)

Task Runtime summary:  (histogram)
rate(celery_tasks_runtime_seconds_sum{job=~"$job"}[$TIME_FRAME])     (/api/tasks: runtime)

Task Latency:  (histogram)
rate(celery_task_latency_sum{job=~"$job"}[$TIME_FRAME])              (/api/tasks: ???)
rate(celery_task_latency_count{job=~"$job"}[$TIME_FRAME])            (/api/tasks: ???)

Top 15 Active tasks:
topk(15, sum(rate(celery_tasks_by_name{job=~"$job", state='STARTED'}[$TIME_FRAME])) by (app, name))     (/api/task: state, name)
(same again for Received, Pending, Failure, Retry, and Success)




Soooo.... I'm building the Flower dashboard for Grafana:

I have:

1) CELERY_WORKERS (Gauge)  [app] with count   (This gives the worker's name)


2) CELERY_TASK_TYPES_BY_STATE ['task_type', 'state'] with count

rate(celery_task_types_by_state{job=~"$job",state="FAILURE"}[5m])
sum(celery_task_types_by_state{job=~"$job",state="FAILURE"}) by (task_type)
sum(celery_task_types_by_state{job=~"$job"}) by (task_type, status)   
sum(celery_task_types_by_state{job=~"$job", state="RECEIVED"}) by (task_type)   <<<<<<<<<<<<<<


3) CELERY_TASKS_BY_NAME ['name', 'state'] with count.  So we can see what is in:
	FAILURE, PENDING, RECEIVED, RETRY, REVOKED, STARTED, and SUCCESS

4) CELERY_TASK_DURATION_BY_STATE ['name', 'runtime', 'state'].set_get_current_time()


Next:

Latency for RECEIVED and PENDING? RETRY?

Runtime for STARTED?

CELERY_TASK_DURATION_BY_STATE ['name', 'state', 'runtime']   
    histogram going into duration buckets, or gauge with `.set_to_current_time()` ???


  histogram??
rate(celery_tasks_runtime_seconds_sum{job=~"$job"}[$TIME_FRAME])

https://prometheus.io/docs/practices/histograms/  (You would use buckets for say, runtimes incurred by various task types, as an example)
See "https://prometheus.io/docs/practices/histograms/#apdex-score"

https://www.robustperception.io/how-does-a-prometheus-histogram-work

Runtime goes into bucket?  Task-name, state, runtime.



Prom types: https://github.com/prometheus/client_python

rate(celery_task_types_by_state{job=~"$job",state="FAILURE"}[5m])

ISSUE WITH RESTARTS, need to be able to add a timeout to the API call.  Code will not allow this extra parameter to be added
as is written.  These restarts are the reason, I beleive, we see gaps in the grafana graphs.

[Requests Module Advanced Docs](https://requests.readthedocs.io/en/master/user/advanced/)

**Cheers!**
